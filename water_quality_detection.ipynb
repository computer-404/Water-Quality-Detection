{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.9531 - accuracy: 0.6596 - val_loss: 0.6119 - val_accuracy: 0.6429\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.6440 - accuracy: 0.5106 - val_loss: 0.6780 - val_accuracy: 0.6429\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.6743 - accuracy: 0.6809 - val_loss: 0.6324 - val_accuracy: 0.6429\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.6326 - accuracy: 0.6596 - val_loss: 0.6061 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.5945 - accuracy: 0.6596 - val_loss: 0.5627 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.5596 - accuracy: 0.6596 - val_loss: 0.5956 - val_accuracy: 0.6429\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.5926 - accuracy: 0.7021 - val_loss: 0.4361 - val_accuracy: 0.6429\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.4578 - accuracy: 0.7447 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.4283 - accuracy: 0.8085 - val_loss: 0.5876 - val_accuracy: 0.6429\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.5123 - accuracy: 0.7234 - val_loss: 0.3266 - val_accuracy: 0.9286\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.4983 - accuracy: 0.7447 - val_loss: 0.3036 - val_accuracy: 0.9286\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.3960 - accuracy: 0.8298 - val_loss: 0.5451 - val_accuracy: 0.6429\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.4946 - accuracy: 0.7234 - val_loss: 0.4066 - val_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.3836 - accuracy: 0.8511 - val_loss: 0.3970 - val_accuracy: 0.9286\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.4690 - accuracy: 0.8085 - val_loss: 0.3998 - val_accuracy: 0.9286\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.4511 - accuracy: 0.8085 - val_loss: 0.3288 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 238ms/step - loss: 0.3672 - accuracy: 0.8298 - val_loss: 0.3797 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 0.3613 - accuracy: 0.8511 - val_loss: 0.3068 - val_accuracy: 0.9286\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.2924 - accuracy: 0.8723 - val_loss: 0.3415 - val_accuracy: 0.7857\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 2s 872ms/step - loss: 0.2798 - accuracy: 0.8298 - val_loss: 0.3676 - val_accuracy: 0.7857\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.2617 - accuracy: 0.8723 - val_loss: 0.3508 - val_accuracy: 0.7857\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 240ms/step - loss: 0.2446 - accuracy: 0.8723 - val_loss: 0.3045 - val_accuracy: 0.9286\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.1939 - accuracy: 0.9362 - val_loss: 0.3033 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 239ms/step - loss: 0.1662 - accuracy: 0.9362 - val_loss: 0.3087 - val_accuracy: 0.9286\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.1277 - accuracy: 0.9574 - val_loss: 0.2672 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.1200 - accuracy: 0.9574 - val_loss: 0.3708 - val_accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 0.1326 - accuracy: 0.9149 - val_loss: 0.2043 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0939 - accuracy: 0.9574 - val_loss: 0.2166 - val_accuracy: 0.9286\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.2503 - val_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9286\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9286\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9286\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9286\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9286\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.9286\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.9286\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9286\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3285 - val_accuracy: 0.9286\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9286\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9286\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 3.5715e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9286\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 2.9148e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9286\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 255ms/step - loss: 4.8626e-04 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.9286\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 180ms/step - loss: 5.0388e-04 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.9286\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 4.2674e-04 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 3.3394e-04 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.9286\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 2.3356e-04 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 1.9122e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9286\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 244ms/step - loss: 1.4081e-04 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9286\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 265ms/step - loss: 1.2796e-04 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9286\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 1.1638e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9286\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 1.1763e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9286\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9286\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 1.1320e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9286\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0889e-04 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9286\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 1.0089e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 9.4572e-05 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9286\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 190ms/step - loss: 8.6310e-05 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 7.8307e-05 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9286\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 229ms/step - loss: 7.2968e-05 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9286\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 6.9191e-05 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.9286\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 211ms/step - loss: 6.4529e-05 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.9286\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 6.2291e-05 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.9286\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 5.9610e-05 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.9286\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 5.8960e-05 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.9286\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 5.6405e-05 - accuracy: 1.0000 - val_loss: 0.5652 - val_accuracy: 0.9286\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 5.5445e-05 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.9286\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 5.4277e-05 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.9286\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 5.2619e-05 - accuracy: 1.0000 - val_loss: 0.5744 - val_accuracy: 0.9286\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 5.0833e-05 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9286\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 4.9042e-05 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.9286\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 4.7872e-05 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.9286\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 265ms/step - loss: 4.6099e-05 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.9286\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 4.5122e-05 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.9286\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 4.3865e-05 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9286\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 4.2672e-05 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.9286\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 246ms/step - loss: 4.1360e-05 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.9286\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 4.0587e-05 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.9286\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 3.9565e-05 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.9286\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 3.8674e-05 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.9286\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7605e-05 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.9286\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 3.6870e-05 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9286\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 493ms/step - loss: 3.6182e-05 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9286\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 3.5397e-05 - accuracy: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9286\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.4601e-05 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.9286\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 233ms/step - loss: 3.4026e-05 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 0.9286\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 3.3375e-05 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.9286\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 3.2737e-05 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.9286\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 3.2048e-05 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.9286\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 3.1557e-05 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9286\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 3.0799e-05 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9286\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 3.0237e-05 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.9286\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 209ms/step - loss: 2.9764e-05 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9286\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 2.9349e-05 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9286\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 2.8656e-05 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.9286\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 2.8225e-05 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.9286\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 2.7724e-05 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.9286\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 243ms/step - loss: 2.7209e-05 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.9286\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6270 - accuracy: 0.9286\n",
      "Test accuracy: 92.86%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load train and test CSV files containing image paths and labels\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Define image size\n",
    "image_size = (150, 150)\n",
    "\n",
    "# Data preprocessing function to load images and labels\n",
    "def preprocess_data(data):\n",
    "    images = []\n",
    "    labels = data['labels'].values\n",
    "    \n",
    "    for img_path in data['file_paths']:\n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        img = img_to_array(img)\n",
    "        img = img / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "    \n",
    "    return np.array(images), labels\n",
    "\n",
    "# Preprocess train and test data\n",
    "train_images, train_labels = preprocess_data(train_data)\n",
    "test_images, test_labels = preprocess_data(test_data)\n",
    "\n",
    "# Create a CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=100, batch_size=32, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masudip/anaconda3/envs/NN/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model as tflite\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
